{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import chainer\n",
    "from chainer import cuda, Variable, FunctionSet, optimizers, serializers ### Add 'serializers'\n",
    "import chainer.functions  as F\n",
    "import chainer.links as L\n",
    "import pdb\n",
    "import argparse\n",
    "from VGGNet import VGGNet\n",
    "from Original_VGGNet import Original_VGGNet\n",
    "import glob\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import cPickle as pickle\n",
    "import cv2\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument('--gpu',default=0,help='GPU ID (default 0)')\n",
    "#parser.add_argument('--model',default=0,help='use pre-trained model or not')\n",
    "#parser.add_argument('--load',default=1,help='LOAD or not (default 1)')\n",
    "#args = parser.parse_args()\n",
    "\n",
    "\n",
    "classes =  [\"aragaki_face\",\"hoshino_face\",\"narita_face\",\"other_face\",\"fujii_face\",\"mano_face\",\"ohtani_face\",\"yamaga_face\"]\n",
    "#load=int(args.load)\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = cPickle.load(fo)\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "def conv_setup(ORIGINAL_VGG,VGG):\n",
    "    VGG.conv1_1 = ORIGINAL_VGG.conv1_1\n",
    "    VGG.conv1_2 = ORIGINAL_VGG.conv1_2\n",
    "    VGG.conv2_1 = ORIGINAL_VGG.conv2_1\n",
    "    VGG.conv2_2 = ORIGINAL_VGG.conv2_2\n",
    "    VGG.conv3_1 = ORIGINAL_VGG.conv3_1\n",
    "    VGG.conv3_2 = ORIGINAL_VGG.conv3_2\n",
    "    VGG.conv3_3 = ORIGINAL_VGG.conv3_3\n",
    "    VGG.conv4_1 = ORIGINAL_VGG.conv4_1\n",
    "    VGG.conv4_2 = ORIGINAL_VGG.conv4_2\n",
    "    VGG.conv4_3 = ORIGINAL_VGG.conv4_3\n",
    "    VGG.conv5_1 = ORIGINAL_VGG.conv5_1\n",
    "    VGG.conv5_2 = ORIGINAL_VGG.conv5_2\n",
    "    VGG.conv5_3 = ORIGINAL_VGG.conv5_3\n",
    "    return VGG\n",
    "\n",
    "\n",
    "def preprocess(x_train, x_test):\n",
    "    print(x_train.shape)\n",
    "    mean = np.mean(x_train, axis=(0, 2, 3), keepdims=True)\n",
    "    return x_train-mean, x_test-mean\n",
    "\n",
    "def augment(x,size):#4D tensor\n",
    "    #flip = np.random.randint(2,size = len(x))*2-1\n",
    "    theta = np.random.uniform(0,2*np.pi,len(x))\n",
    "    scale = np.random.uniform(0.9,1.2,len(x)).reshape(-1,1,1)\n",
    "    shift = np.random.uniform(-5,5,len(x)*2).reshape(-1,2)\n",
    "    xs = np.arange(size**2)%size\n",
    "    ys = np.arange(size**2)/size\n",
    "    coords = np.c_[xs,ys].transpose()-size/2.#変換前の座標\n",
    "    R = scale*(np.c_[np.cos(theta),-np.sin(theta),np.sin(theta),np.cos(theta)].reshape(len(x),2,2))\n",
    "    img = np.array([X[:,np.clip(np.dot(r,coords)[1]+size/2.+s[1],0,size-1).astype('int32'),np.clip(np.dot(r,coords)[0]+size/2.+s[0],0,size-1).astype('int32')].reshape(3,size,size) for s,r,X in zip(shift,R,x)])\n",
    "    return img\n",
    "\n",
    "def load_faces():\n",
    "    data_dir = \"/home/mil/noguchi/seminar/face/faces_nparray/\"\n",
    "    classes =  [\"aragaki_face\",\"hoshino_face\",\"narita_face\",\"other_face\",\"fujii_face\",\"mano_face\",\"ohtani_face\",\"yamaga_face\"]\n",
    "    X=[]\n",
    "    y=[]\n",
    "    \n",
    "    for i, cls in enumerate(classes):\n",
    "        X_=np.load(data_dir+cls+\".npy\").astype(np.uint8)\n",
    "        kkk=np.array([cv2.resize(ll,((96,96))).transpose(2,0,1)/255. for ll in X_])\n",
    "        X.extend(kkk)\n",
    "        y.extend(np.ones(len(kkk),dtype=np.int32)*i)\n",
    "    X = np.array(X,dtype=np.float32)\n",
    "    y = np.array(y,dtype=np.int32)\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid_train():\n",
    "    with open('vgg.pkl', 'rb') as i:\n",
    "        orig_vgg = pickle.load(i)\n",
    "    vgg=VGGNet()\n",
    "    #if int(args.model) == 1:\n",
    "    #orig_vgg = Original_VGGNet()\n",
    "    #serializers.load_hdf5('VGG.model', orig_vgg)\n",
    "    vgg = conv_setup(orig_vgg,vgg)\n",
    "    print 'loading data now.'\n",
    "    \n",
    "    #if not load :\n",
    "    X,y = load_faces()\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    \n",
    "    print 'loading data done'\n",
    "    x_train,x_test = preprocess(x_train,x_test)\n",
    "    batchsize = 30\n",
    "    N = len(x_train)\n",
    "    N_test = len(x_test)\n",
    "    n_epoch = 50\n",
    "    #gpu = int(args.gpu)\n",
    "    optimizer = optimizers.MomentumSGD(lr=0.002,momentum=0.9)\n",
    "    \n",
    "    optimizer.setup(vgg)\n",
    "    optimizer.add_hook(chainer.optimizer.WeightDecay(0.001))\n",
    "    vgg.to_gpu()\n",
    "    \n",
    "    for epoch in xrange(1, n_epoch+1):\n",
    "        \n",
    "        if epoch in [35,45]:\n",
    "            optimizer.lr*=0.20\n",
    "        print 'epoch', epoch\n",
    "        # training\n",
    "        perm = np.random.permutation(N)\n",
    "        sum_loss = 0\n",
    "        for i in xrange(0, N, batchsize):\n",
    "            x_batch = cuda.to_gpu(augment(x_train[perm[i:i+batchsize]],96))\n",
    "            y_batch = cuda.to_gpu(y_train[perm[i:i+batchsize]])\n",
    "            optimizer.zero_grads()\n",
    "            loss,_,_ = vgg(x_batch, y_batch, train=True)\n",
    "            loss.backward()\n",
    "            optimizer.update()\n",
    "            sum_loss     += float(cuda.to_cpu(loss.data)) * len(x_batch)\n",
    "\n",
    "        print 'train mean loss={}'.format(sum_loss / N)\n",
    "        \n",
    "        # evaluation\n",
    "        sum_accuracy = 0\n",
    "        \n",
    "        pred_y =[]\n",
    "        for i in xrange(0, N_test, batchsize):\n",
    "            x_batch = cuda.to_gpu(x_test[i:i+batchsize])\n",
    "            y_batch = cuda.to_gpu(y_test[i:i+batchsize])\n",
    "\n",
    "            _,acc,pred = vgg(x_batch,y_batch,train=False)\n",
    "            pred_y.extend(np.argmax(cuda.to_cpu(pred.data),axis=1))\n",
    "            sum_accuracy += float(cuda.to_cpu(acc.data)) * len(x_batch)\n",
    "\n",
    "        print 'test mean accuracy={}'.format(sum_accuracy / N_test)\n",
    "        for i in range(len(classes)):\n",
    "            accuracy = np.sum((np.array(pred_y)==y_test)*(y_test==i))*1./np.sum(y_test==i)\n",
    "            print '    {} accuracy={}'.format(classes[i],accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    with open('vgg.pkl', 'rb') as i:\n",
    "        orig_vgg = pickle.load(i)\n",
    "    vgg=VGGNet()\n",
    "    #if int(args.model) == 1:\n",
    "    #orig_vgg = Original_VGGNet()\n",
    "    #serializers.load_hdf5('VGG.model', orig_vgg)\n",
    "    vgg = conv_setup(orig_vgg,vgg)\n",
    "    print 'loading data now.'\n",
    "    \n",
    "    #if not load :\n",
    "    X,y_train = load_faces()\n",
    "    \n",
    "    print 'loading data done'\n",
    "    x_train,_= preprocess(X,[])\n",
    "    batchsize = 30\n",
    "    N = len(x_train)\n",
    "    n_epoch = 40\n",
    "    #gpu = int(args.gpu)\n",
    "    optimizer = optimizers.MomentumSGD(lr=0.002,momentum=0.9)\n",
    "    \n",
    "    optimizer.setup(vgg)\n",
    "    optimizer.add_hook(chainer.optimizer.WeightDecay(0.001))\n",
    "    vgg.to_gpu()\n",
    "    \n",
    "    for epoch in xrange(1, n_epoch+1):\n",
    "        \n",
    "        if epoch in [30,35]:\n",
    "            optimizer.lr*=0.1\n",
    "        print 'epoch', epoch\n",
    "        # training\n",
    "        perm = np.random.permutation(N)\n",
    "        sum_loss = 0\n",
    "        for i in xrange(0, N, batchsize):\n",
    "            x_batch = cuda.to_gpu(augment(x_train[perm[i:i+batchsize]],96))\n",
    "            y_batch = cuda.to_gpu(y_train[perm[i:i+batchsize]])\n",
    "            optimizer.zero_grads()\n",
    "            loss,_,_ = vgg(x_batch, y_batch, train=True)\n",
    "            loss.backward()\n",
    "            optimizer.update()\n",
    "            sum_loss     += float(cuda.to_cpu(loss.data)) * len(x_batch)\n",
    "\n",
    "        print 'train mean loss={}'.format(sum_loss / N)\n",
    "        \n",
    "    serializers.save_hdf5('VGG11_{}.model'.format(str(sum_loss/N).replace('.','')), vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ =='__main__':\n",
    "    valid_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
